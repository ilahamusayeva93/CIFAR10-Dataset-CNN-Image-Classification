{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOLBXrcLEb1Z",
    "outputId": "ce331e09-bc08-4f0a-f7d7-36f9293aece5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "num_epochs=50\n",
    "learning_rate=0.001\n",
    "batch_size=128\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "train_dataset=torchvision.datasets.CIFAR10(root='./data',train=True,transform=transform,download=True)\n",
    "test_dataset=torchvision.datasets.CIFAR10(root='./data',train=False,transform=transform,download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "syLzIXQ1XPnK",
    "outputId": "4db18b00-8772-44f7-fee7-471f8cadccf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "IfK1VariXPpj"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkvZj2_cXPrl",
    "outputId": "b02cff37-9db9-4794-b0fd-8f251f7cb882"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZD7y6tvHXzcl",
    "outputId": "f2273a5d-c0e4-4e7c-8516-97ded21ae7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/313], Loss: 1.5179927349090576\n",
      "Epoch [1/50], Step [200/313], Loss: 1.4036657810211182\n",
      "Epoch [1/50], Step [300/313], Loss: 1.245557188987732\n",
      "Epoch [1/50] - Validation Accuracy: 58.32%\n",
      "Epoch [2/50], Step [100/313], Loss: 1.2021178007125854\n",
      "Epoch [2/50], Step [200/313], Loss: 1.098151445388794\n",
      "Epoch [2/50], Step [300/313], Loss: 0.7357503175735474\n",
      "Epoch [2/50] - Validation Accuracy: 60.32%\n",
      "Epoch [3/50], Step [100/313], Loss: 0.7284601330757141\n",
      "Epoch [3/50], Step [200/313], Loss: 0.911190390586853\n",
      "Epoch [3/50], Step [300/313], Loss: 0.981538712978363\n",
      "Epoch [3/50] - Validation Accuracy: 67.01%\n",
      "Epoch [4/50], Step [100/313], Loss: 0.6408079266548157\n",
      "Epoch [4/50], Step [200/313], Loss: 0.7199646830558777\n",
      "Epoch [4/50], Step [300/313], Loss: 0.6706714630126953\n",
      "Epoch [4/50] - Validation Accuracy: 67.71%\n",
      "Epoch [5/50], Step [100/313], Loss: 0.7189332246780396\n",
      "Epoch [5/50], Step [200/313], Loss: 0.665956437587738\n",
      "Epoch [5/50], Step [300/313], Loss: 0.6318879723548889\n",
      "Epoch [5/50] - Validation Accuracy: 72.95%\n",
      "Epoch [6/50], Step [100/313], Loss: 0.5559581518173218\n",
      "Epoch [6/50], Step [200/313], Loss: 0.6743982434272766\n",
      "Epoch [6/50], Step [300/313], Loss: 0.5382255911827087\n",
      "Epoch [6/50] - Validation Accuracy: 69.05%\n",
      "Epoch [7/50], Step [100/313], Loss: 0.5156158208847046\n",
      "Epoch [7/50], Step [200/313], Loss: 0.47436779737472534\n",
      "Epoch [7/50], Step [300/313], Loss: 0.49646157026290894\n",
      "Epoch [7/50] - Validation Accuracy: 73.11%\n",
      "Epoch [8/50], Step [100/313], Loss: 0.41280317306518555\n",
      "Epoch [8/50], Step [200/313], Loss: 0.447752982378006\n",
      "Epoch [8/50], Step [300/313], Loss: 0.4980979859828949\n",
      "Epoch [8/50] - Validation Accuracy: 76.64%\n",
      "Epoch [9/50], Step [100/313], Loss: 0.4997968375682831\n",
      "Epoch [9/50], Step [200/313], Loss: 0.4409792721271515\n",
      "Epoch [9/50], Step [300/313], Loss: 0.4173738956451416\n",
      "Epoch [9/50] - Validation Accuracy: 73.75%\n",
      "Epoch [10/50], Step [100/313], Loss: 0.5866124033927917\n",
      "Epoch [10/50], Step [200/313], Loss: 0.40811797976493835\n",
      "Epoch [10/50], Step [300/313], Loss: 0.3310319483280182\n",
      "Epoch [10/50] - Validation Accuracy: 75.92%\n",
      "Epoch [11/50], Step [100/313], Loss: 0.22512851655483246\n",
      "Epoch [11/50], Step [200/313], Loss: 0.3155817687511444\n",
      "Epoch [11/50], Step [300/313], Loss: 0.2970947325229645\n",
      "Epoch [11/50] - Validation Accuracy: 73.01%\n",
      "Epoch [12/50], Step [100/313], Loss: 0.27308881282806396\n",
      "Epoch [12/50], Step [200/313], Loss: 0.3112789988517761\n",
      "Epoch [12/50], Step [300/313], Loss: 0.260911226272583\n",
      "Epoch [12/50] - Validation Accuracy: 74.28%\n",
      "Epoch [13/50], Step [100/313], Loss: 0.16611644625663757\n",
      "Epoch [13/50], Step [200/313], Loss: 0.15920567512512207\n",
      "Epoch [13/50], Step [300/313], Loss: 0.3136126697063446\n",
      "Epoch [13/50] - Validation Accuracy: 75.12%\n",
      "Early stopping. No improvement in validation accuracy.\n",
      "Test Accuracy: 76.64%\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(4 * 4 * 128, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 512)\n",
    "        self.fc3 = nn.Linear(512, 100)\n",
    "        self.fc4 = nn.Linear(100, 10)\n",
    "        self.drop_out = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.fc4(out)\n",
    "        return out\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "model = ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "total_step = len(train_loader)\n",
    "best_val_accuracy = 0.0\n",
    "patience = 5\n",
    "counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item()}')\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        val_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}] - Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), 'best_convnet_model.pth')\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping. No improvement in validation accuracy.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load('best_convnet_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-1bVXQwXzg5",
    "outputId": "fd0b2549-4b85-448e-cf66-887050ecc1b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: deer Predicted: deer\n",
      "True: ship Predicted: truck\n",
      "True: truck Predicted: truck\n",
      "True: airplane Predicted: airplane\n",
      "True: truck Predicted: truck\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "labels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "for _ in range(5):\n",
    "    random_index = randint(1,10000)\n",
    "    image, label = test_dataset[random_index]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image.unsqueeze(0))\n",
    "\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "\n",
    "    print(\"True:\", labels[label], \"Predicted:\", labels[predicted])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
